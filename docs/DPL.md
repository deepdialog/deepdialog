# 对话策略（Dialog Policy） 模块

也有一些资料把这部分称为 Policy Optimization / Policy Learning。

对话策略模块可以认为是根据对话历史状态进行决策的一个部件，当然历史上DPL本身有很多发展过程，例如用部分可观察马尔可夫随机过程的方式建模（POMDP），当然现代研究主要都转向了使用神经网络。我们这里不回归历史，我们这里讨论两种训练方法。

## 直接有监督训练

直接有监督的训练比较好理解，首先我们定义一些训练流程。

其次就是在对话过程中计算这些流程变化中的对话状态和应该的系统行为作为有监督训练数据。

最后放入训练模型训练。

## 基于强化学习的训练

基于强化学习的训练主要是要考虑如何模拟一个用户，并且在关键时刻给予用户奖励（reward）
